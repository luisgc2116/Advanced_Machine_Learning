{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation_seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisgc2116/Machine-Learning/blob/master/Translation_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "301cd8ea-d65a-4bcb-da3c-4918e35ed270",
        "id": "OQGA9FVYaI-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Data at: http://www.manythings.org/anki/\n",
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "import os, sys\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
        "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras.backend as K\n",
        "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
        "  from keras.layers import CuDNNLSTM as LSTM\n",
        "  from keras.layers import CuDNNGRU as GRU\n",
        "\n",
        "  \n",
        "# make sure we do softmax over the time axis\n",
        "# expected shape is N x T x D\n",
        "# note: the latest version of Keras allows you to pass in axis arg\n",
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e / s\n",
        "\n",
        "# Basic configurations\n",
        "BATCH_SIZE = 64  \n",
        "EPOCHS = 100  \n",
        "LATENT_DIMENSIONALITY = 256  \n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_NUM_OF_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "# Separate data into inputs and targets\n",
        "input_texts = [] \n",
        "target_texts = [] \n",
        "target_texts_inputs = []\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 10000  \n",
        "num_samples = 0\n",
        "#file_path = '/content/drive/My Drive/spa (1).txt'\n",
        "file_path_language = 'spa.txt'\n",
        "for line in open(file_path_language, encoding=\"utf-8\"):\n",
        "  \n",
        "  # keep track of limit of samples\n",
        "  num_samples += 1\n",
        "  if num_samples > NUM_TRAIN_SAMPLES:\n",
        "    break\n",
        "\n",
        "  # input and target are separated by tab\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "\n",
        "  # Separate input text and the translation into our sec language\n",
        "  input_text, translation = line.rstrip().split('\\t')\n",
        "\n",
        "  # Make target input and output using the sentence tags\n",
        "  target_input = '<sos> ' + translation\n",
        "  target = translation + ' <eos>'\n",
        "\n",
        "\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target)\n",
        "  target_texts_inputs.append(target_input)\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MvWVDzOTaLhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7b138a3c-3c8f-48c7-e994-af43377cd584"
      },
      "cell_type": "code",
      "source": [
        "# Tokenize inputs\n",
        "tokenize_inputs = Tokenizer(num_words=MAX_NUM_OF_WORDS)\n",
        "tokenize_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenize_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "# Word-to-index mapping for our input language\n",
        "word2idx_inputs = tokenize_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "\n",
        "# Tokenize outputs, but don't filter out <sos> and <eos> \n",
        "tokenize_outputs = Tokenizer(num_words=MAX_NUM_OF_WORDS, filters='')\n",
        "tokenize_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
        "target_sequences = tokenize_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenize_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenize_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# determine maximum length output sequence\n",
        "max_len_target = max(len(s) for s in target_sequences)\n",
        "\n",
        "\n",
        "# Caculate max length input sequence for later padding \n",
        "max_len_input = max(len(s) for s in input_sequences)\n",
        "\n",
        "# Padding sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2364 unique input tokens.\n",
            "Found 6294 unique output tokens.\n",
            "encoder_inputs.shape: (10000, 5)\n",
            "encoder_inputs[0]: [ 0  0  0  0 14]\n",
            "decoder_inputs[0]: [   2 1480    0    0    0    0    0    0    0]\n",
            "decoder_inputs.shape: (10000, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KoJLQiLWawH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "85999278-3b45-4591-ef4a-baaccb0c4b3d"
      },
      "cell_type": "code",
      "source": [
        "# Create word-to-vec dict \n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "#path_word2vec = #'/content/drive/My Drive/glove.6B.%sd.txt'\n",
        "path_word2vec = \"glove.6B.%sd.txt\"\n",
        "with open(os.path.join(path_word2vec % EMBEDDING_DIM), encoding=\"utf-8\") as f:\n",
        "  # Space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Embedding matrix\n",
        "# Words not found word2vec become vectors of 0s\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_NUM_OF_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_OF_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "# Vector/Embedding layer\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        "  # trainable=True\n",
        ")\n",
        "\n",
        "\n",
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "decoder_targets_categorical_encoded = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n",
        "\n",
        "# assign the values\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    decoder_targets_categorical_encoded[i, t, word] = 1"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n",
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OgadRrkYoCp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3784
        },
        "outputId": "1c6e8eb5-c478-4f23-e50a-464d6b490330"
      },
      "cell_type": "code",
      "source": [
        "##### build the model #####\n",
        "\n",
        "LATENT_DIM_DECODER = 256 \n",
        "\n",
        "# Set up the encoder - simple!\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = Bidirectional(LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        "))\n",
        "encoder_outputs = encoder(x)\n",
        "\n",
        "\n",
        "# Set up the decoder - not so simple\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "######### Attention #########\n",
        "# Attention layers need to be global because\n",
        "# they will be repeated Ty times at the decoder\n",
        "attn_repeat_layer = RepeatVector(max_len_input)\n",
        "attn_concat_layer = Concatenate(axis=-1)\n",
        "attn_dense1 = Dense(10, activation='tanh')\n",
        "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
        "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
        "\n",
        "def one_step_attention(h, st_1):\n",
        "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
        "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
        " \n",
        "  # copy s(t-1) Tx times\n",
        "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
        "  st_1 = attn_repeat_layer(st_1)\n",
        "\n",
        "  # Concatenate all h(t)'s with s(t-1)\n",
        "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
        "  x = attn_concat_layer([h, st_1])\n",
        "\n",
        "  # Neural net first layer\n",
        "  x = attn_dense1(x)\n",
        "\n",
        "  # Neural net second layer with special softmax over time\n",
        "  alphas = attn_dense2(x)\n",
        "\n",
        "  # \"Dot\" the alphas and the h's\n",
        "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
        "  context = attn_dot([alphas, h])\n",
        "\n",
        "  return context\n",
        "\n",
        "\n",
        "# define the rest of the decoder (after attention)\n",
        "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "\n",
        "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
        "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
        "context_last_word_concat_layer = Concatenate(axis=2)\n",
        "\n",
        "\n",
        "# Unlike previous seq2seq, we cannot get the output\n",
        "# all in one step\n",
        "# Instead we need to do Ty steps\n",
        "# And in each of those steps, we need to consider\n",
        "# all Tx h's\n",
        "\n",
        "# s, c will be re-assigned in each iteration of the loop\n",
        "s = initial_s\n",
        "c = initial_c\n",
        "\n",
        "# collect outputs in a list at first\n",
        "outputs = []\n",
        "for t in range(max_len_target): # Ty times\n",
        "  # get the context using attention\n",
        "  context = one_step_attention(encoder_outputs, s)\n",
        "\n",
        "  # we need a different layer for each time step\n",
        "  selector = Lambda(lambda x: x[:, t:t+1])\n",
        "  xt = selector(decoder_inputs_x)\n",
        "  \n",
        "  # combine \n",
        "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
        "\n",
        "  # pass the combined [context, last word] into the LSTM\n",
        "  # along with [s, c]\n",
        "  # get the new [s, c] and output\n",
        "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
        "\n",
        "  # final dense layer to get next word prediction\n",
        "  decoder_outputs = decoder_dense(o)\n",
        "  outputs.append(decoder_outputs)\n",
        "\n",
        "\n",
        "# 'outputs' is now a list of length Ty\n",
        "# each element is of shape (batch size, output vocab size)\n",
        "# therefore if we simply stack all the outputs into 1 tensor\n",
        "# it would be of shape T x N x D\n",
        "# we would like it to be of shape N x T x D\n",
        "\n",
        "def stack_and_transpose(x):\n",
        "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
        "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
        "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
        "  return x\n",
        "\n",
        "# make it a layer\n",
        "stacker = Lambda(stack_and_transpose)\n",
        "outputs = stacker(outputs)\n",
        "\n",
        "# create the model\n",
        "model = Model(\n",
        "  inputs=[\n",
        "    encoder_inputs_placeholder,\n",
        "    decoder_inputs_placeholder,\n",
        "    initial_s, \n",
        "    initial_c,\n",
        "  ],\n",
        "  outputs=outputs\n",
        ")\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "z = np.zeros((NUM_TRAIN_SAMPLES, LATENT_DIM_DECODER)) # initial [s, c]\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2\n",
        ")\n",
        "\n",
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7114 - acc: 0.6380 - val_loss: 2.7059 - val_acc: 0.6511\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 2.0619 - acc: 0.7096 - val_loss: 2.4403 - val_acc: 0.6711\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.8474 - acc: 0.7280 - val_loss: 2.2803 - val_acc: 0.6847\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.6850 - acc: 0.7464 - val_loss: 2.1757 - val_acc: 0.7029\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.5552 - acc: 0.7619 - val_loss: 2.1068 - val_acc: 0.7114\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.4451 - acc: 0.7761 - val_loss: 2.0293 - val_acc: 0.7216\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.3476 - acc: 0.7882 - val_loss: 1.9857 - val_acc: 0.7301\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.2657 - acc: 0.7980 - val_loss: 1.9534 - val_acc: 0.7354\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.1949 - acc: 0.8073 - val_loss: 1.9475 - val_acc: 0.7397\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.1306 - acc: 0.8166 - val_loss: 1.9358 - val_acc: 0.7436\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.0709 - acc: 0.8248 - val_loss: 1.9088 - val_acc: 0.7438\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 1.0124 - acc: 0.8322 - val_loss: 1.8966 - val_acc: 0.7451\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.9581 - acc: 0.8407 - val_loss: 1.8708 - val_acc: 0.7504\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.9111 - acc: 0.8479 - val_loss: 1.8701 - val_acc: 0.7511\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.8621 - acc: 0.8547 - val_loss: 1.8629 - val_acc: 0.7510\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.8211 - acc: 0.8614 - val_loss: 1.8598 - val_acc: 0.7536\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.7880 - acc: 0.8673 - val_loss: 1.8916 - val_acc: 0.7483\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.7552 - acc: 0.8724 - val_loss: 1.8696 - val_acc: 0.7499\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.7210 - acc: 0.8776 - val_loss: 1.8884 - val_acc: 0.7496\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.6895 - acc: 0.8829 - val_loss: 1.9134 - val_acc: 0.7463\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.6595 - acc: 0.8870 - val_loss: 1.9139 - val_acc: 0.7453\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.6271 - acc: 0.8917 - val_loss: 1.9116 - val_acc: 0.7415\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5990 - acc: 0.8956 - val_loss: 1.9309 - val_acc: 0.7424\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5793 - acc: 0.8992 - val_loss: 1.9446 - val_acc: 0.7386\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5610 - acc: 0.9027 - val_loss: 1.9628 - val_acc: 0.7390\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5416 - acc: 0.9060 - val_loss: 1.9781 - val_acc: 0.7391\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5238 - acc: 0.9080 - val_loss: 1.9843 - val_acc: 0.7376\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5043 - acc: 0.9105 - val_loss: 2.0035 - val_acc: 0.7369\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4899 - acc: 0.9132 - val_loss: 2.0123 - val_acc: 0.7368\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4783 - acc: 0.9160 - val_loss: 2.0029 - val_acc: 0.7372\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4663 - acc: 0.9174 - val_loss: 2.0418 - val_acc: 0.7330\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4549 - acc: 0.9185 - val_loss: 2.0396 - val_acc: 0.7354\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4439 - acc: 0.9210 - val_loss: 2.0465 - val_acc: 0.7344\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4332 - acc: 0.9218 - val_loss: 2.0530 - val_acc: 0.7362\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4223 - acc: 0.9236 - val_loss: 2.0669 - val_acc: 0.7334\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4107 - acc: 0.9249 - val_loss: 2.0802 - val_acc: 0.7333\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3995 - acc: 0.9265 - val_loss: 2.1026 - val_acc: 0.7319\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3906 - acc: 0.9279 - val_loss: 2.1124 - val_acc: 0.7327\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3812 - acc: 0.9305 - val_loss: 2.1054 - val_acc: 0.7323\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3736 - acc: 0.9307 - val_loss: 2.1133 - val_acc: 0.7336\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3672 - acc: 0.9330 - val_loss: 2.1329 - val_acc: 0.7299\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3604 - acc: 0.9330 - val_loss: 2.1286 - val_acc: 0.7318\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3556 - acc: 0.9335 - val_loss: 2.1449 - val_acc: 0.7314\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3491 - acc: 0.9355 - val_loss: 2.1416 - val_acc: 0.7296\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3428 - acc: 0.9370 - val_loss: 2.1643 - val_acc: 0.7293\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3326 - acc: 0.9385 - val_loss: 2.1636 - val_acc: 0.7276\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3230 - acc: 0.9405 - val_loss: 2.1618 - val_acc: 0.7296\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3187 - acc: 0.9409 - val_loss: 2.1888 - val_acc: 0.7281\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3145 - acc: 0.9412 - val_loss: 2.1775 - val_acc: 0.7291\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3110 - acc: 0.9423 - val_loss: 2.1957 - val_acc: 0.7281\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3073 - acc: 0.9427 - val_loss: 2.1948 - val_acc: 0.7283\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3039 - acc: 0.9430 - val_loss: 2.2064 - val_acc: 0.7269\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3001 - acc: 0.9440 - val_loss: 2.2020 - val_acc: 0.7274\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2964 - acc: 0.9442 - val_loss: 2.1996 - val_acc: 0.7270\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2920 - acc: 0.9454 - val_loss: 2.2021 - val_acc: 0.7276\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2888 - acc: 0.9455 - val_loss: 2.2223 - val_acc: 0.7266\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2853 - acc: 0.9459 - val_loss: 2.2245 - val_acc: 0.7273\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2821 - acc: 0.9465 - val_loss: 2.2389 - val_acc: 0.7253\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2785 - acc: 0.9472 - val_loss: 2.2536 - val_acc: 0.7267\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2749 - acc: 0.9477 - val_loss: 2.2558 - val_acc: 0.7241\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2727 - acc: 0.9481 - val_loss: 2.2419 - val_acc: 0.7252\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2697 - acc: 0.9479 - val_loss: 2.2519 - val_acc: 0.7245\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2675 - acc: 0.9486 - val_loss: 2.2536 - val_acc: 0.7264\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2649 - acc: 0.9488 - val_loss: 2.2678 - val_acc: 0.7246\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2627 - acc: 0.9495 - val_loss: 2.2684 - val_acc: 0.7252\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2607 - acc: 0.9497 - val_loss: 2.2655 - val_acc: 0.7254\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2599 - acc: 0.9493 - val_loss: 2.2731 - val_acc: 0.7233\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2590 - acc: 0.9492 - val_loss: 2.2732 - val_acc: 0.7246\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2569 - acc: 0.9497 - val_loss: 2.2969 - val_acc: 0.7244\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2559 - acc: 0.9500 - val_loss: 2.2894 - val_acc: 0.7238\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2546 - acc: 0.9500 - val_loss: 2.2983 - val_acc: 0.7232\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2531 - acc: 0.9506 - val_loss: 2.2935 - val_acc: 0.7236\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2520 - acc: 0.9508 - val_loss: 2.3079 - val_acc: 0.7229\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2510 - acc: 0.9503 - val_loss: 2.3044 - val_acc: 0.7227\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2488 - acc: 0.9509 - val_loss: 2.3198 - val_acc: 0.7233\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2474 - acc: 0.9517 - val_loss: 2.3088 - val_acc: 0.7237\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2461 - acc: 0.9514 - val_loss: 2.3192 - val_acc: 0.7222\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2447 - acc: 0.9510 - val_loss: 2.3211 - val_acc: 0.7226\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2433 - acc: 0.9518 - val_loss: 2.3200 - val_acc: 0.7220\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2419 - acc: 0.9518 - val_loss: 2.3389 - val_acc: 0.7226\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2402 - acc: 0.9521 - val_loss: 2.3373 - val_acc: 0.7232\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2393 - acc: 0.9522 - val_loss: 2.3451 - val_acc: 0.7221\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2378 - acc: 0.9523 - val_loss: 2.3520 - val_acc: 0.7225\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2365 - acc: 0.9526 - val_loss: 2.3560 - val_acc: 0.7215\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2359 - acc: 0.9526 - val_loss: 2.3672 - val_acc: 0.7223\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2344 - acc: 0.9530 - val_loss: 2.3682 - val_acc: 0.7205\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2341 - acc: 0.9527 - val_loss: 2.3515 - val_acc: 0.7220\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2337 - acc: 0.9529 - val_loss: 2.3620 - val_acc: 0.7222\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2332 - acc: 0.9532 - val_loss: 2.3769 - val_acc: 0.7212\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2329 - acc: 0.9532 - val_loss: 2.3796 - val_acc: 0.7230\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2320 - acc: 0.9531 - val_loss: 2.3749 - val_acc: 0.7233\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2312 - acc: 0.9531 - val_loss: 2.3860 - val_acc: 0.7226\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2310 - acc: 0.9537 - val_loss: 2.3902 - val_acc: 0.7233\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2301 - acc: 0.9535 - val_loss: 2.3842 - val_acc: 0.7218\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2297 - acc: 0.9538 - val_loss: 2.3997 - val_acc: 0.7216\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2293 - acc: 0.9535 - val_loss: 2.3993 - val_acc: 0.7219\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2291 - acc: 0.9538 - val_loss: 2.3963 - val_acc: 0.7233\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2289 - acc: 0.9543 - val_loss: 2.3996 - val_acc: 0.7225\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2290 - acc: 0.9536 - val_loss: 2.4015 - val_acc: 0.7228\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 0.2289 - acc: 0.9540 - val_loss: 2.4025 - val_acc: 0.7218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NfvQJBbNpbpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "0c39ee89-7349-47f4-8739-3dab18814436"
      },
      "cell_type": "code",
      "source": [
        "##### Make predictions #####\n",
        "# As with the poetry example, we need to create another model\n",
        "# that can take in the RNN state and previous word as input\n",
        "# and accept a T=1 sequence.\n",
        "\n",
        "# The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "# i.e. h(1), ..., h(Tx)\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
        "\n",
        "# next we define a T=1 decoder model\n",
        "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "# no need to loop over attention steps this time because there is only one step\n",
        "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
        "\n",
        "# combine context with last word\n",
        "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
        "\n",
        "# lstm and final dense\n",
        "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
        "decoder_outputs = decoder_dense(o)\n",
        "\n",
        "\n",
        "# note: we don't really need the final stack and tranpose\n",
        "# because there's only 1 output\n",
        "# it is already of size N x D\n",
        "# no need to make it 1 x N x D --> N x 1 x D\n",
        "\n",
        "\n",
        "\n",
        "# create the model object\n",
        "decoder_model = Model(\n",
        "  inputs=[\n",
        "    decoder_inputs_single,\n",
        "    encoder_outputs_as_input,\n",
        "    initial_s, \n",
        "    initial_c\n",
        "  ],\n",
        "  outputs=[decoder_outputs, s, c]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  enc_out = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  \n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "\n",
        "  # [s, c] will be updated in each loop iteration\n",
        "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
        "\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
        "        \n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(o.flatten())\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "  return ' '.join(output_sentence)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input sentence:', input_texts[i])\n",
        "  print('Predicted translation:', translation)\n",
        "  print('Actual translation:', target_texts[i])\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Out of my way!\n",
            "Predicted translation: ¡fuera de mi camino!\n",
            "Actual translation: ¡Fuera de mi camino! <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: Tom died young.\n",
            "Predicted translation: tom murió joven.\n",
            "Actual translation: Tom murió joven. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: Will you go?\n",
            "Predicted translation: ¿va a ir?\n",
            "Actual translation: ¿Va a ir? <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: How lovely!\n",
            "Predicted translation: ¡qué bonito!\n",
            "Actual translation: ¡Es una preciosidad! <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: What gives?\n",
            "Predicted translation: ¿qué hay?\n",
            "Actual translation: ¿Qué pasa? <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: I'm educated.\n",
            "Predicted translation: tengo formación.\n",
            "Actual translation: Tengo formación. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: I'm finicky.\n",
            "Predicted translation: soy quisquilloso.\n",
            "Actual translation: Soy quisquilloso. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: We have a plan.\n",
            "Predicted translation: tenemos un plan.\n",
            "Actual translation: Tenemos un plan. <eos>\n",
            "Continue? [Y/n]N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aY1PvWGta6VN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4301
        },
        "outputId": "4b01072b-225d-4199-a3fb-5677536acc94"
      },
      "cell_type": "code",
      "source": [
        "##### build the model #####\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(\n",
        "  LATENT_DIMENSIONALITY,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "# encoder_outputs, h = encoder(x) #gru\n",
        "\n",
        "# keep only the states to pass into decoder\n",
        "encoder_states = [h, c]\n",
        "# encoder_states = [state_h] # gru\n",
        "\n",
        "# Set up the decoder, using [h, c] as initial state.\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, LATENT_DIMENSIONALITY)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "# since the decoder is a \"to-many\" model we want to have\n",
        "# return_sequences=True\n",
        "decoder_lstm = LSTM(\n",
        "  LATENT_DIMENSIONALITY,\n",
        "  return_sequences=True,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "  decoder_inputs_x,\n",
        "  initial_state=encoder_states\n",
        ")\n",
        "\n",
        "# decoder_outputs, _ = decoder_gru(\n",
        "#   decoder_inputs_x,\n",
        "#   initial_state=encoder_states\n",
        "# )\n",
        "\n",
        "# final dense layer for predictions\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Create the model object\n",
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
        "\n",
        "# Compile the model and train it\n",
        "model.compile(\n",
        "  optimizer='rmsprop',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs], decoder_targets_categorical_encoded,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "\n",
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['acc'], label='acc')\n",
        "plt.plot(r.history['val_acc'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save('s2s.h5')\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 7s 898us/step - loss: 2.6380 - acc: 0.6593 - val_loss: 2.5789 - val_acc: 0.6579\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 2.0155 - acc: 0.7144 - val_loss: 2.3929 - val_acc: 0.6743\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 1.8072 - acc: 0.7362 - val_loss: 2.2471 - val_acc: 0.6899\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 1.6478 - acc: 0.7542 - val_loss: 2.1567 - val_acc: 0.7067\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 1.5172 - acc: 0.7683 - val_loss: 2.0685 - val_acc: 0.7198\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 1.4083 - acc: 0.7825 - val_loss: 2.0077 - val_acc: 0.7307\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 6s 701us/step - loss: 1.3148 - acc: 0.7938 - val_loss: 1.9718 - val_acc: 0.7343\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 1.2322 - acc: 0.8024 - val_loss: 1.9539 - val_acc: 0.7399\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 6s 703us/step - loss: 1.1599 - acc: 0.8115 - val_loss: 1.9540 - val_acc: 0.7377\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 1.0924 - acc: 0.8195 - val_loss: 1.9396 - val_acc: 0.7394\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 6s 702us/step - loss: 1.0311 - acc: 0.8280 - val_loss: 1.9419 - val_acc: 0.7351\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 6s 701us/step - loss: 0.9738 - acc: 0.8350 - val_loss: 1.9509 - val_acc: 0.7333\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 6s 700us/step - loss: 0.9220 - acc: 0.8422 - val_loss: 1.9571 - val_acc: 0.7323\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.8732 - acc: 0.8503 - val_loss: 1.9652 - val_acc: 0.7321\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 5s 687us/step - loss: 0.8269 - acc: 0.8562 - val_loss: 1.9664 - val_acc: 0.7334\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 6s 693us/step - loss: 0.7859 - acc: 0.8628 - val_loss: 1.9628 - val_acc: 0.7349\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.7488 - acc: 0.8676 - val_loss: 2.0123 - val_acc: 0.7296\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.7157 - acc: 0.8733 - val_loss: 2.0042 - val_acc: 0.7313\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 0.6849 - acc: 0.8782 - val_loss: 2.0346 - val_acc: 0.7286\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.6537 - acc: 0.8831 - val_loss: 2.0421 - val_acc: 0.7294\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.6227 - acc: 0.8878 - val_loss: 2.0470 - val_acc: 0.7286\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 0.5948 - acc: 0.8916 - val_loss: 2.0409 - val_acc: 0.7286\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 6s 694us/step - loss: 0.5657 - acc: 0.8960 - val_loss: 2.0714 - val_acc: 0.7287\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.5415 - acc: 0.8996 - val_loss: 2.0839 - val_acc: 0.7286\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.5205 - acc: 0.9035 - val_loss: 2.0845 - val_acc: 0.7298\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 6s 700us/step - loss: 0.4980 - acc: 0.9067 - val_loss: 2.0964 - val_acc: 0.7303\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.4794 - acc: 0.9100 - val_loss: 2.1177 - val_acc: 0.7294\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 6s 700us/step - loss: 0.4618 - acc: 0.9124 - val_loss: 2.1330 - val_acc: 0.7284\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.4432 - acc: 0.9152 - val_loss: 2.1483 - val_acc: 0.7276\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.4285 - acc: 0.9181 - val_loss: 2.1572 - val_acc: 0.7293\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 6s 688us/step - loss: 0.4128 - acc: 0.9201 - val_loss: 2.1864 - val_acc: 0.7299\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 5s 686us/step - loss: 0.3993 - acc: 0.9222 - val_loss: 2.1826 - val_acc: 0.7291\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 6s 692us/step - loss: 0.3877 - acc: 0.9242 - val_loss: 2.2138 - val_acc: 0.7280\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.3751 - acc: 0.9262 - val_loss: 2.2160 - val_acc: 0.7289\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.3653 - acc: 0.9280 - val_loss: 2.2478 - val_acc: 0.7266\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.3555 - acc: 0.9299 - val_loss: 2.2486 - val_acc: 0.7267\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.3447 - acc: 0.9311 - val_loss: 2.2666 - val_acc: 0.7272\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.3338 - acc: 0.9331 - val_loss: 2.2963 - val_acc: 0.7257\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 6s 694us/step - loss: 0.3228 - acc: 0.9355 - val_loss: 2.2948 - val_acc: 0.7268\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.3147 - acc: 0.9361 - val_loss: 2.3037 - val_acc: 0.7275\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.3065 - acc: 0.9383 - val_loss: 2.3007 - val_acc: 0.7282\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.2987 - acc: 0.9397 - val_loss: 2.3262 - val_acc: 0.7262\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 6s 693us/step - loss: 0.2908 - acc: 0.9400 - val_loss: 2.3320 - val_acc: 0.7289\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.2843 - acc: 0.9418 - val_loss: 2.3340 - val_acc: 0.7262\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.2784 - acc: 0.9429 - val_loss: 2.3523 - val_acc: 0.7275\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2735 - acc: 0.9438 - val_loss: 2.3497 - val_acc: 0.7253\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2682 - acc: 0.9450 - val_loss: 2.3766 - val_acc: 0.7254\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2627 - acc: 0.9462 - val_loss: 2.3594 - val_acc: 0.7262\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2590 - acc: 0.9461 - val_loss: 2.3817 - val_acc: 0.7254\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.2535 - acc: 0.9473 - val_loss: 2.3696 - val_acc: 0.7263\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.2491 - acc: 0.9478 - val_loss: 2.3817 - val_acc: 0.7248\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.2455 - acc: 0.9488 - val_loss: 2.3817 - val_acc: 0.7248\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 6s 692us/step - loss: 0.2406 - acc: 0.9494 - val_loss: 2.3972 - val_acc: 0.7240\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.2367 - acc: 0.9497 - val_loss: 2.3977 - val_acc: 0.7231\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.2324 - acc: 0.9507 - val_loss: 2.4061 - val_acc: 0.7229\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.2292 - acc: 0.9513 - val_loss: 2.3869 - val_acc: 0.7233\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.2259 - acc: 0.9520 - val_loss: 2.4093 - val_acc: 0.7233\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 6s 694us/step - loss: 0.2229 - acc: 0.9522 - val_loss: 2.4163 - val_acc: 0.7236\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.2190 - acc: 0.9533 - val_loss: 2.3978 - val_acc: 0.7243\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 6s 701us/step - loss: 0.2172 - acc: 0.9531 - val_loss: 2.4154 - val_acc: 0.7222\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.2144 - acc: 0.9537 - val_loss: 2.4287 - val_acc: 0.7217\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.2122 - acc: 0.9533 - val_loss: 2.4239 - val_acc: 0.7241\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2097 - acc: 0.9536 - val_loss: 2.4071 - val_acc: 0.7218\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2082 - acc: 0.9544 - val_loss: 2.4255 - val_acc: 0.7243\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.2058 - acc: 0.9547 - val_loss: 2.4189 - val_acc: 0.7231\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.2036 - acc: 0.9549 - val_loss: 2.4215 - val_acc: 0.7248\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.2013 - acc: 0.9551 - val_loss: 2.4314 - val_acc: 0.7228\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 6s 693us/step - loss: 0.1996 - acc: 0.9548 - val_loss: 2.4333 - val_acc: 0.7234\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.1977 - acc: 0.9556 - val_loss: 2.4303 - val_acc: 0.7232\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 0.1966 - acc: 0.9554 - val_loss: 2.4335 - val_acc: 0.7215\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 6s 694us/step - loss: 0.1961 - acc: 0.9553 - val_loss: 2.4419 - val_acc: 0.7221\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.1948 - acc: 0.9555 - val_loss: 2.4331 - val_acc: 0.7228\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.1941 - acc: 0.9557 - val_loss: 2.4502 - val_acc: 0.7224\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 0.1937 - acc: 0.9556 - val_loss: 2.4353 - val_acc: 0.7227\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.1924 - acc: 0.9557 - val_loss: 2.4517 - val_acc: 0.7220\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.1921 - acc: 0.9561 - val_loss: 2.4553 - val_acc: 0.7221\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.1912 - acc: 0.9563 - val_loss: 2.4520 - val_acc: 0.7208\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.1914 - acc: 0.9559 - val_loss: 2.4626 - val_acc: 0.7214\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.1911 - acc: 0.9557 - val_loss: 2.4592 - val_acc: 0.7225\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.1910 - acc: 0.9563 - val_loss: 2.4739 - val_acc: 0.7222\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.1906 - acc: 0.9557 - val_loss: 2.4771 - val_acc: 0.7215\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.1898 - acc: 0.9562 - val_loss: 2.4818 - val_acc: 0.7215\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.1903 - acc: 0.9563 - val_loss: 2.4703 - val_acc: 0.7219\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.1898 - acc: 0.9570 - val_loss: 2.4865 - val_acc: 0.7226\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 6s 698us/step - loss: 0.1890 - acc: 0.9567 - val_loss: 2.4858 - val_acc: 0.7218\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.1891 - acc: 0.9567 - val_loss: 2.4878 - val_acc: 0.7211\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 6s 688us/step - loss: 0.1888 - acc: 0.9568 - val_loss: 2.4974 - val_acc: 0.7198\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 5s 686us/step - loss: 0.1891 - acc: 0.9568 - val_loss: 2.4946 - val_acc: 0.7212\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 6s 693us/step - loss: 0.1882 - acc: 0.9572 - val_loss: 2.5007 - val_acc: 0.7221\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 6s 692us/step - loss: 0.1887 - acc: 0.9566 - val_loss: 2.4986 - val_acc: 0.7205\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 6s 692us/step - loss: 0.1892 - acc: 0.9566 - val_loss: 2.4999 - val_acc: 0.7206\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 0.1895 - acc: 0.9573 - val_loss: 2.4999 - val_acc: 0.7220\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 6s 690us/step - loss: 0.1907 - acc: 0.9568 - val_loss: 2.5019 - val_acc: 0.7205\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 6s 699us/step - loss: 0.1911 - acc: 0.9567 - val_loss: 2.5019 - val_acc: 0.7198\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.1915 - acc: 0.9570 - val_loss: 2.5079 - val_acc: 0.7216\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.1925 - acc: 0.9569 - val_loss: 2.5080 - val_acc: 0.7210\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 6s 696us/step - loss: 0.1935 - acc: 0.9571 - val_loss: 2.5055 - val_acc: 0.7209\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 6s 695us/step - loss: 0.1938 - acc: 0.9576 - val_loss: 2.5129 - val_acc: 0.7205\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 6s 697us/step - loss: 0.1946 - acc: 0.9566 - val_loss: 2.5166 - val_acc: 0.7206\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 6s 693us/step - loss: 0.1957 - acc: 0.9570 - val_loss: 2.4969 - val_acc: 0.7222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAYQoQBADCECAMAYAgRBgDAkB/tkH8ug6o2VQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4VdHUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer cu_dnnlstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'cu_dnnlstm_1/strided_slice_16:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'cu_dnnlstm_1/strided_slice_17:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sMvCURnzhx3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "d1ae05c9-2eba-4ea2-91ac-d04d05b7cee2"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "##### Make predictions #####\n",
        "# As with the poetry example, we need to create another model\n",
        "# that can take in the RNN state and previous word as input\n",
        "# and accept a T=1 sequence.\n",
        "\n",
        "# The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIMENSIONALITY,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIMENSIONALITY,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "# this time, we want to keep the states too, to be output\n",
        "# by our sampling model\n",
        "decoder_outputs, h, c = decoder_lstm(\n",
        "  decoder_inputs_single_x,\n",
        "  initial_state=decoder_states_inputs\n",
        ")\n",
        "# decoder_outputs, state_h = decoder_lstm(\n",
        "#   decoder_inputs_single_x,\n",
        "#   initial_state=decoder_states_inputs\n",
        "# ) #gru\n",
        "decoder_states = [h, c]\n",
        "# decoder_states = [h] # gru\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# The sampling model\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\n",
        "# outputs: y(t), h(t), c(t)\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs_single] + decoder_states_inputs,\n",
        "  [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: I study English.\n",
            "Translation: estudio francés.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I get by.\n",
            "Translation: me las arreglo.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: Leave a message.\n",
            "Translation: sal a una encanta el no te yo la\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: Is he Japanese?\n",
            "Translation: ¿es él japonés?\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I'm freezing.\n",
            "Translation: estoy helado.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I see the crown.\n",
            "Translation: veo una veo de\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I can't say.\n",
            "Translation: no puedo decir.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: She's my sister.\n",
            "Translation: ella es mi esposa.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I am weak.\n",
            "Translation: estoy débil.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: The boy is kind.\n",
            "Translation: el eres un adora de es gentil.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: Let's come back.\n",
            "Translation: la vuelve para arriba.\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R9w4kEYFoMjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_sequence):\n",
        "  # Encode the input as state vectors.\n",
        "  state_val = encoder_model.predict(input_sequence)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + state_val\n",
        "    )\n",
        "    # output_tokens, h = decoder_model.predict(\n",
        "    #     [target_seq] + state_val\n",
        "    # ) # gru\n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "    # Update states\n",
        "    state_val = [h, c]\n",
        "    # state_val = [h] # gru\n",
        "\n",
        "  return ' '.join(output_sentence)\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_sequence = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_sequence)\n",
        "  print('-')\n",
        "  print('Input:', input_texts[i])\n",
        "  print('Translation:', translation)\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}